{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuanChenhang/USAAIO/blob/main/PyTorch_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary libraries**"
      ],
      "metadata": {
        "id": "bMbzXE0-KSFw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKrvX6-FFn37"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a Dataset class**\n",
        "\n",
        "Three build-in methods:\n",
        "\n",
        "* Initialization: ```__init__```\n",
        "* Length: ```__len__```\n",
        "* Indexing and slicing: ```__getitem__```"
      ],
      "metadata": {
        "id": "X9D5M9RQKVh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Build a dataset class to construct an image dataset**\n",
        "\n",
        "* Raw dataset\n",
        "    * Image data in numpy with shape ```(batch_size, height, width, num_channels)```\n",
        "    * Labels\n",
        "\n",
        "*  Dataset to construct\n",
        "    * Image data in tensor with shape ```(batch_size, num_channels, height, width)``` and is normalized within 0 and 1\n",
        "    * Labels"
      ],
      "metadata": {
        "id": "GrDPC4VlKzhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a raw dataset\n",
        "\n",
        "num_samples = 10\n",
        "size = (4, 8, 3) # shape of each sample (height, width, num_channels)\n",
        "num_classes = 5\n",
        "\n",
        "images = np.random.randint(low = 0, high = 256, size = (num_samples, *size), dtype = np.uint8)\n",
        "labels = np.random.randint(low = 0, high = num_classes, size = (num_samples,), dtype = np.int64)"
      ],
      "metadata": {
        "id": "KhamkN1kL6e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, images_numpy, labels):\n",
        "        self.images_tensor = torch.from_numpy(images_numpy).to(torch.float32) / 255\n",
        "        self.images_tensor = self.images_tensor.permute(0, 3, 1, 2)\n",
        "        self.labels = torch.from_numpy(labels).to(torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images_tensor.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images_tensor[index]\n",
        "        label = self.labels[index]\n",
        "        # Method 1 of return: Separate items\n",
        "        return image, label\n",
        "\n",
        "        # Method 2 of return: Dictionary\n",
        "        # return {'image': image, 'label': label}\n",
        "\n"
      ],
      "metadata": {
        "id": "OQtLWRNOGAlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct dataset\n",
        "\n",
        "dataset = MyDataset(images, labels)\n",
        "print(len(dataset))\n",
        "print(dataset[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFMMD9IHpmi",
        "outputId": "77161204-b47e-495c-aaef-b59a2281e0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "(tensor([[[0.3294, 0.1765, 0.7098, 0.3020, 0.7294, 0.6078, 0.1137, 0.1176],\n",
            "         [0.2471, 0.8157, 0.2784, 0.3137, 0.2392, 0.4706, 0.9843, 0.7804],\n",
            "         [0.4353, 0.5490, 0.4275, 0.0235, 0.2588, 0.0353, 0.2078, 0.7882],\n",
            "         [0.1373, 0.0549, 0.4353, 0.0863, 0.0353, 0.6627, 0.1255, 0.5216]],\n",
            "\n",
            "        [[0.3490, 0.9333, 1.0000, 0.2353, 0.0157, 0.6510, 0.4941, 0.8353],\n",
            "         [0.4549, 0.9686, 0.5922, 0.9490, 0.5922, 0.1059, 0.0078, 0.6784],\n",
            "         [0.1373, 0.5529, 0.4275, 0.1529, 0.4902, 0.3137, 0.5569, 0.7725],\n",
            "         [0.1137, 0.4745, 0.2824, 0.7529, 0.2275, 0.6863, 0.7686, 0.3569]],\n",
            "\n",
            "        [[0.9686, 0.0000, 0.9725, 0.9961, 0.0471, 0.4588, 0.1176, 0.4078],\n",
            "         [0.2000, 0.6118, 0.8588, 0.6706, 0.8431, 0.4039, 0.6863, 0.2745],\n",
            "         [0.8039, 0.7686, 0.8039, 0.5059, 0.6588, 0.6196, 0.3333, 0.8824],\n",
            "         [0.6510, 0.5882, 0.9608, 0.2588, 0.6039, 0.6588, 0.2078, 0.6039]]]), tensor(0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise: Build a dataset for next-sentence prediction (NSP)**\n",
        "\n",
        "* **Raw dataset**\n",
        "    * Each sample consists of two sentences that follow a logical relation.\n",
        "    * Each sample's data format: A list with two items. Each item is a 1-dim tensor with each token represented by its ID.\n",
        "    * The end of each sentence is a special token with ID 2.\n",
        "    * While generating tokens, avoid using special token IDs 0, 1, 2.\n",
        "\n",
        "* **Dataset to construct**\n",
        "    * For each sample, fix the first sentence and create multiple subsamples for the second sentences. The second sentences include the ground-truth one and other sentences randomly drawn form the dataset.\n",
        "    * Each pair of sentences is labeled as ```True``` if they follow the ground-truth logic and ```False``` otherwise.\n",
        "    * Format of each sentence:\n",
        "    ```torch.cat([torch.tensor([1]), sen1, sen2], dim = 0)```\n",
        "\n",
        "* **Key ideas**\n",
        "    * Negative sampling\n",
        "    * Data augmentation"
      ],
      "metadata": {
        "id": "nVzZTOxuLx4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build a raw dataset**"
      ],
      "metadata": {
        "id": "ibVsvX15OzYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10\n",
        "vocab_size = 30 # token IDs: 0, 1, ..., vocab_size - 1\n",
        "length_LB = 5\n",
        "length_UB = 12\n",
        "\n",
        "raw_dataset = []\n",
        "for n in range(num_samples):\n",
        "    # Generate sentence 1\n",
        "    length_sen1 = torch.randint(low = length_LB, high = length_UB, size = ())\n",
        "    sen1 = torch.randint(low = 3, high = vocab_size, size = (length_sen1,))\n",
        "    sen1 = torch.cat([sen1, torch.tensor([2])], dim = 0)\n",
        "\n",
        "    # Generate sentence 2\n",
        "    length_sen2 = torch.randint(low = length_LB, high = length_UB, size = ())\n",
        "    sen2 = torch.randint(low = 3, high = vocab_size, size = (length_sen2,))\n",
        "    sen2 = torch.cat([sen2, torch.tensor([2])], dim = 0)\n",
        "\n",
        "    # Put two sentences to a list\n",
        "    raw_dataset.append([sen1, sen2])"
      ],
      "metadata": {
        "id": "asP4sJPOOy2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Dataset class**"
      ],
      "metadata": {
        "id": "e2VgIsryRDv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNSPDataset(Dataset):\n",
        "    def __init__(self, raw_dataset, num_noisy_samples):\n",
        "        num_samples_raw = len(raw_dataset) # Number of samples in the raw dataset\n",
        "        self.num_samples = num_samples_raw * (1 + num_noisy_samples) # Number of samples in the dataset that we are constructing\n",
        "        self.inputs = [] # List of all paired sentences\n",
        "        self.labels = [] # List of labels of all paired sentences\n",
        "\n",
        "        # Extract sentence 1s and 2s, respectively, from the raw dataset\n",
        "        sen1_raw_list = []\n",
        "        sen2_raw_list = []\n",
        "        for n in range(num_samples_raw):\n",
        "            sen1_raw_list.append(raw_dataset[n][0])\n",
        "            sen2_raw_list.append(raw_dataset[n][1])\n",
        "\n",
        "        # Compute probability distribution of sentence 2s that are randomly drawn\n",
        "        prob_sen2_indices = 1/num_samples_raw * torch.ones(num_samples_raw)\n",
        "\n",
        "        for n in range(num_samples_raw):\n",
        "            # Add the nth ground-truth pair of sentences to the dataset\n",
        "            self.inputs.append(torch.cat([torch.tensor([1]), sen1_raw_list[n], sen2_raw_list[n]]))\n",
        "            self.labels.append(torch.tensor(True))\n",
        "\n",
        "            # Randomly generate sentence 2 indices\n",
        "            sen2_indices = torch.multinomial(input = prob_sen2_indices, num_samples = num_noisy_samples, replacement = True)\n",
        "\n",
        "            # Add the nth sentence 1 and each randomly selected sentence 2 to the dataset\n",
        "            for m in range(num_noisy_samples):\n",
        "                self.inputs.append(torch.cat([torch.tensor([1]), sen1_raw_list[n], sen2_raw_list[sen2_indices[m]]]))\n",
        "                self.labels.append(sen2_indices[m] == n)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input = self.inputs[index]\n",
        "        label = self.labels[index]\n",
        "        return {'input': input, 'label': label}\n"
      ],
      "metadata": {
        "id": "pnZKQxilP2Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct dataset**"
      ],
      "metadata": {
        "id": "96pO0OseY1Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_NSP = MyNSPDataset(raw_dataset, 2)\n",
        "print(len(dataset_NSP))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4USEeypvVqG5",
        "outputId": "197e13f5-89d2-4098-e51d-7a58e0eb2b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copyright  Beaver-Edge AI Institute. All Rights Reserved. No part of this document may be copied or reproduced without the written permission of Beaver-Edge AI Institute.**"
      ],
      "metadata": {
        "id": "tlG2rK3rniDN"
      }
    }
  ]
}
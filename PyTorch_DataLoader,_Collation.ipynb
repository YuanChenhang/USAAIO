{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuanChenhang/USAAIO/blob/main/PyTorch_DataLoader%2C_Collation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary libraries**"
      ],
      "metadata": {
        "id": "bMbzXE0-KSFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cuKr8JkO_ob5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DataLoader**"
      ],
      "metadata": {
        "id": "Jjo-jx5KRA-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoader**: A DataLoader object\n",
        "\n",
        "* partitions a dataset into batches\n",
        "* is an iterable that consists of these batches\n",
        "\n",
        "```\n",
        "dataloader = DataLoader(dataset, batch_size = ..., shuffle = ..., drop_last = ..., collate_fn = ...)\n",
        "```\n",
        "\n",
        "* dataset: Dictionary format\n",
        "\n",
        "```\n",
        "dataset[index] = {key_0: val_0[index], ..., key_{M-1}: val_{M-1}[index]}\n",
        "```\n",
        "\n",
        "* ```batch_size```: Number of samples in each batch\n",
        "\n",
        "* ```shuffle```: Whether dataset indices in a batch are in order\n",
        "\n",
        "* ```drop_last```: Whether dropping out the last batch if its size is smaller than the batch size\n",
        "\n",
        "Each item in **dataloader**:\n",
        "\n",
        "```\n",
        "batch = {key_0: batch_val_0, ..., key_{M-1}: batch_val_{M-1}}\n",
        "```\n",
        "\n",
        "* Let $B$ be the set of indices of samples that are in the batch. For each ```key_m```,\n",
        "\n",
        "```\n",
        "batch_val_m = torch.stack([val_m[index] for index in B], dim = 0)\n",
        "```\n",
        "\n",
        "**Collate function** ```collate_fn```: For each key ```key_m```, make ```val_m[index]``` **$\\color{red}{\\text{the same shape for all indices}}$**\n",
        "\n",
        "* If ```val_m[index]``` has the same shape for all indices, then we use DataLoader's default function ```collate_fn```.\n",
        "\n",
        "* Otherwise, create a customized ```collate_fn```.\n",
        "\n"
      ],
      "metadata": {
        "id": "4uoohz9dRG5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Build a dataloader object with the image dataset that we built in Chapter \"PyTorch - Dataset\"**\n",
        "\n",
        "* Raw dataset\n",
        "    * Image data in numpy with shape ```(batch_size, height, width, num_channels)```\n",
        "    * Labels\n",
        "\n",
        "*  Dataset to construct\n",
        "    * Image data in tensor with shape ```(batch_size, num_channels, height, width)``` and is normalized within 0 and 1\n",
        "    * Labels"
      ],
      "metadata": {
        "id": "GrDPC4VlKzhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a raw dataset\n",
        "\n",
        "num_samples = 100\n",
        "size = (128, 256, 3) # shape of each sample (height, width, num_channels)\n",
        "num_classes = 5\n",
        "\n",
        "images = np.random.randint(low = 0, high = 256, size = (num_samples, *size), dtype = np.uint8)\n",
        "labels = np.random.randint(low = 0, high = num_classes, size = (num_samples,), dtype = np.int64)"
      ],
      "metadata": {
        "id": "KhamkN1kL6e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, images_numpy, labels):\n",
        "        self.images_tensor = torch.from_numpy(images_numpy).to(torch.float32) / 255\n",
        "        self.images_tensor = self.images_tensor.permute(0, 3, 1, 2)\n",
        "        self.labels = torch.from_numpy(labels).to(torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images_tensor.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images_tensor[index]\n",
        "        label = self.labels[index]\n",
        "        return {'image': image, 'label': label, 'sample_index': torch.tensor(index)}"
      ],
      "metadata": {
        "id": "OQtLWRNOGAlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct dataset\n",
        "dataset = MyDataset(images, labels)\n",
        "print(type(dataset[0]))\n",
        "print(dataset[0].keys())\n",
        "print(dataset[0]['image'].shape)\n",
        "print(dataset[0]['label'].shape)\n",
        "print(dataset[0]['sample_index'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFMMD9IHpmi",
        "outputId": "776bad9d-6289-4cb0-89b6-f8faa797b7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['image', 'label', 'sample_index'])\n",
            "torch.Size([3, 128, 256])\n",
            "torch.Size([])\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build dataloader with the default ```collate_fn```**"
      ],
      "metadata": {
        "id": "UYlKTCTpVWNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True, drop_last = False, collate_fn = None)\n",
        "\n",
        "batch = next(iter(dataloader))\n",
        "print(type(batch))\n",
        "print(batch['image'].shape)\n",
        "print(batch['label'].shape)\n",
        "print(batch['sample_index'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHbueQXEO9L_",
        "outputId": "0cba4463-ec70-49ed-8ff3-1af3c3fbfd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "torch.Size([4, 3, 128, 256])\n",
            "torch.Size([4])\n",
            "tensor([45, 99, 83, 96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Collation functions**"
      ],
      "metadata": {
        "id": "Dk4ngvGgc1Y1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build dataloader with a customized ```collate_fn```**\n",
        "\n",
        "* Input argument that ```dataloader``` sends to a collate function:\n",
        "\n",
        "    * A list whose length is the batch size\n",
        "    * Each item in the list is ```dataset[index]```"
      ],
      "metadata": {
        "id": "ZbGLb_jDW-7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_collate_fn(batch_before_collation):\n",
        "    '''\n",
        "    # Let us understand the input argument that dataloader sends to this collate function\n",
        "    print(\"batch before collation:\", batch_before_collation)\n",
        "    print(\"type of batch before collation:\", type(batch_before_collation))\n",
        "    print(\"length of batch before collation:\", len(batch_before_collation))\n",
        "    print(\"One item in batch_before_collation:\", batch_before_collation[0])\n",
        "    print(\"type of one item in batch_before_collation:\", type(batch_before_collation[0]))\n",
        "\n",
        "    index_in_dataset = batch_before_collation[0]['sample_index'] # Find index in dataset\n",
        "    print([torch.all(batch_before_collation[0][key] == dataset[index_in_dataset][key]) for key in batch_before_collation[0].keys()])\n",
        "    '''\n",
        "\n",
        "    batch_size = len(batch_before_collation) # Compute batch size\n",
        "    dictionary = {key: []  for key in batch_before_collation[0].keys() } # Initialize dictionary\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        for key in dictionary.keys():\n",
        "            dictionary[key].append(batch_before_collation[i][key])\n",
        "\n",
        "    # Construct a collated batch\n",
        "    batch = dict()\n",
        "    for key in dictionary.keys():\n",
        "        batch[key] = torch.stack(dictionary[key], dim = 0)\n",
        "    return batch"
      ],
      "metadata": {
        "id": "3Ul77XkkXC9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True, drop_last = False, collate_fn = my_collate_fn)\n",
        "\n",
        "batch = next(iter(dataloader))\n",
        "print(type(batch))\n",
        "print(batch['image'].shape)\n",
        "print(batch['label'].shape)\n",
        "print(batch['sample_index'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssc2YEv9XTn2",
        "outputId": "c62212fd-6c02-4633-d7d2-fe22156acc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "torch.Size([4, 3, 128, 256])\n",
            "torch.Size([4])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise: Build a dataloader for the Next Sentence Prediction (NSP) whose dataset was built in Chapter \"PyTorch - Dataset\"**"
      ],
      "metadata": {
        "id": "nj4YQMFvdSJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NSP dataset:**\n",
        "\n",
        "* Each sample is a dictionary with keys ```input``` and ```label```\n",
        "* An input is the concatenation of two sequences of token IDs"
      ],
      "metadata": {
        "id": "IncEjtvqeRgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build a raw dataset**"
      ],
      "metadata": {
        "id": "ibVsvX15OzYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10\n",
        "vocab_size = 30 # token IDs: 0, 1, ..., vocab_size - 1\n",
        "length_LB = 5\n",
        "length_UB = 12\n",
        "\n",
        "raw_dataset = []\n",
        "for n in range(num_samples):\n",
        "    # Generate sentence 1\n",
        "    length_sen1 = torch.randint(low = length_LB, high = length_UB, size = ())\n",
        "    sen1 = torch.randint(low = 3, high = vocab_size, size = (length_sen1,))\n",
        "    sen1 = torch.cat([sen1, torch.tensor([2])], dim = 0)\n",
        "\n",
        "    # Generate sentence 2\n",
        "    length_sen2 = torch.randint(low = length_LB, high = length_UB, size = ())\n",
        "    sen2 = torch.randint(low = 3, high = vocab_size, size = (length_sen2,))\n",
        "    sen2 = torch.cat([sen2, torch.tensor([2])], dim = 0)\n",
        "\n",
        "    # Put two sentences to a list\n",
        "    raw_dataset.append([sen1, sen2])"
      ],
      "metadata": {
        "id": "asP4sJPOOy2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Dataset class**"
      ],
      "metadata": {
        "id": "e2VgIsryRDv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNSPDataset(Dataset):\n",
        "    def __init__(self, raw_dataset, num_noisy_samples):\n",
        "        num_samples_raw = len(raw_dataset) # Number of samples in the raw dataset\n",
        "        self.num_samples = num_samples_raw * (1 + num_noisy_samples) # Number of samples in the dataset that we are constructing\n",
        "        self.inputs = [] # List of all paired sentences\n",
        "        self.labels = [] # List of labels of all paired sentences\n",
        "\n",
        "        # Extract sentence 1s and 2s, respectively, from the raw dataset\n",
        "        sen1_raw_list = []\n",
        "        sen2_raw_list = []\n",
        "        for n in range(num_samples_raw):\n",
        "            sen1_raw_list.append(raw_dataset[n][0])\n",
        "            sen2_raw_list.append(raw_dataset[n][1])\n",
        "\n",
        "        # Compute probability distribution of sentence 2s that are randomly drawn\n",
        "        prob_sen2_indices = 1/num_samples_raw * torch.ones(num_samples_raw)\n",
        "\n",
        "        for n in range(num_samples_raw):\n",
        "            # Add the nth ground-truth pair of sentences to the dataset\n",
        "            self.inputs.append(torch.cat([torch.tensor([1]), sen1_raw_list[n], sen2_raw_list[n]]))\n",
        "            self.labels.append(torch.tensor(True))\n",
        "\n",
        "            # Randomly generate sentence 2 indices\n",
        "            sen2_indices = torch.multinomial(input = prob_sen2_indices, num_samples = num_noisy_samples, replacement = True)\n",
        "\n",
        "            # Add the nth sentence 1 and each randomly selected sentence 2 to the dataset\n",
        "            for m in range(num_noisy_samples):\n",
        "                self.inputs.append(torch.cat([torch.tensor([1]), sen1_raw_list[n], sen2_raw_list[sen2_indices[m]]]))\n",
        "                self.labels.append(sen2_indices[m] == n)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input = self.inputs[index]\n",
        "        label = self.labels[index]\n",
        "        return {'input': input, 'label': label}\n"
      ],
      "metadata": {
        "id": "pnZKQxilP2Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct dataset**"
      ],
      "metadata": {
        "id": "96pO0OseY1Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_NSP = MyNSPDataset(raw_dataset, 2)"
      ],
      "metadata": {
        "id": "4USEeypvVqG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a customized collate function**\n",
        "\n",
        "* Inputs from different samples are with different lengths\n",
        "* Shorter inputs shall be padded with token ID 0\n",
        "* After padding, all inputs in a batch are with the same length"
      ],
      "metadata": {
        "id": "ehcoaJ4qezgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_NSP_fn(batch_before_collation):\n",
        "    batch_size = len(batch_before_collation)\n",
        "    dictionary = {key: []  for key in batch_before_collation[0].keys() } # Initialize dictionary\n",
        "    for i in range(batch_size):\n",
        "        for key in dictionary.keys():\n",
        "            dictionary[key].append(batch_before_collation[i][key])\n",
        "\n",
        "    length_inputs = [dictionary['input'][i].shape[0] for i in range(batch_size)]\n",
        "    max_length = max(length_inputs)\n",
        "\n",
        "    # Padding\n",
        "    for i in range(batch_size):\n",
        "        dictionary['input'][i] = torch.cat([dictionary['input'][i], torch.zeros(max_length - length_inputs[i], \\\n",
        "                                                    dtype = torch.int64)], dim = 0)\n",
        "\n",
        "    # Construct a collated batch\n",
        "    batch = dict()\n",
        "    for key in dictionary.keys():\n",
        "        batch[key] = torch.stack(dictionary[key], dim = 0)\n",
        "    return batch"
      ],
      "metadata": {
        "id": "mFoDwneGe3Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a dataloader for the NSP task**"
      ],
      "metadata": {
        "id": "lbkKfbSKge-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "dataloader_NSP = DataLoader(dataset_NSP, batch_size = batch_size, shuffle = True, collate_fn = collate_NSP_fn)\n",
        "\n",
        "batch = next(iter(dataloader_NSP))\n",
        "print(batch['input'].shape)\n",
        "print(batch['label'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x47khxk3gjuA",
        "outputId": "528128ea-d3ed-4068-8cae-8785fceac57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 24])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copyright  Beaver-Edge AI Institute. All Rights Reserved. No part of this document may be copied or reproduced without the written permission of Beaver-Edge AI Institute.**"
      ],
      "metadata": {
        "id": "tlG2rK3rniDN"
      }
    }
  ]
}